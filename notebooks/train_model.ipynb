{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Satellite-Based Crop Health Detection using CNN and NDVI\n",
    "\n",
    "This notebook trains a Convolutional Neural Network (CNN) to classify crop health from preprocessed satellite NDVI images. The goal is to create a model that can accurately distinguish between 'Healthy', 'Rust-infected', and 'Other' stress conditions in crops, providing a valuable tool for precision agriculture.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrandom\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptim\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import tifffile\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Configuration\n",
    "IMG_SIZE = 64\n",
    "CLASSES = ['Health', 'Rust', 'Other']\n",
    "DATA_DIR = \"data/raw/train\"\n",
    "RED_IDX = 44\n",
    "NIR_IDX = 89\n",
    "EPOCHS = 50\n",
    "BATCH_SIZE = 32\n",
    "PATIENCE = 7  # for early stopping\n",
    "\n",
    "# Dataset\n",
    "class HyperspectralDataset(Dataset):\n",
    "    def __init__(self, files, labels, transform=None):\n",
    "        self.files = files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = tifffile.imread(self.files[idx])\n",
    "        ndvi = (img[:, :, NIR_IDX] - img[:, :, RED_IDX]) / (img[:, :, NIR_IDX] + img[:, :, RED_IDX] + 1e-8)\n",
    "        ndvi = np.clip(ndvi, -1, 1)\n",
    "        ndvi = np.nan_to_num(ndvi)\n",
    "        ndvi = cv2.resize(ndvi, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_AREA)\n",
    "        ndvi = ((ndvi + 1) / 2.0).astype(np.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            ndvi = self.transform(ndvi)\n",
    "\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return ndvi, label\n",
    "\n",
    "# CNN Model\n",
    "class CropHealthCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CropHealthCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(8 * 8 * 128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, len(CLASSES))\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Load file paths\n",
    "def load_data():\n",
    "    all_files = []\n",
    "    all_labels = []\n",
    "    label_map = {cls: idx for idx, cls in enumerate(CLASSES)}\n",
    "    for cls in CLASSES:\n",
    "        cls_dir = os.path.join(DATA_DIR, cls)\n",
    "        files = [os.path.join(cls_dir, f) for f in os.listdir(cls_dir) if f.endswith('.tif')]\n",
    "        all_files.extend(files)\n",
    "        all_labels.extend([label_map[cls]] * len(files))\n",
    "    return train_test_split(all_files, all_labels, test_size=0.2, stratify=all_labels, random_state=42)\n",
    "\n",
    "# Training function\n",
    "def train():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    X_train, X_val, y_train, y_val = load_data()\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "    ])\n",
    "    val_transform = transforms.ToTensor()\n",
    "\n",
    "    train_ds = HyperspectralDataset(X_train, y_train, transform)\n",
    "    val_ds = HyperspectralDataset(X_val, y_val, val_transform)\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "    model = CropHealthCNN().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3, verbose=True)\n",
    "\n",
    "    best_val_acc = 0\n",
    "    trigger = 0\n",
    "    train_accs, val_accs = [], []\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        total_loss, correct, total = 0, 0, 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(x)\n",
    "            loss = criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            correct += (outputs.argmax(1) == y).sum().item()\n",
    "            total += y.size(0)\n",
    "\n",
    "        train_acc = correct / total\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        val_preds, val_labels = [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                outputs = model(x)\n",
    "                preds = outputs.argmax(1)\n",
    "                correct += (preds == y).sum().item()\n",
    "                total += y.size(0)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_labels.extend(y.cpu().numpy())\n",
    "\n",
    "        val_acc = correct / total\n",
    "        val_accs.append(val_acc)\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Train Acc = {train_acc:.4f}, Val Acc = {val_acc:.4f}\")\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_preds = val_preds.copy()\n",
    "            best_targets = val_labels.copy()\n",
    "            torch.save(model.state_dict(), \"best_crop_health_cnn.pth\")\n",
    "            trigger = 0\n",
    "        else:\n",
    "            trigger += 1\n",
    "            if trigger >= PATIENCE:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    print(\"\\nâœ… Best Validation Accuracy:\", best_val_acc)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(best_targets, best_preds, target_names=CLASSES))\n",
    "\n",
    "    cm = confusion_matrix(best_targets, best_preds)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=CLASSES, yticklabels=CLASSES)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return train_accs, val_accs\n",
    "\n",
    "# Plot training curve\n",
    "def plot(train_accs, val_accs):\n",
    "    plt.plot(train_accs, label=\"Train Accuracy\")\n",
    "    plt.plot(val_accs, label=\"Val Accuracy\")\n",
    "    plt.title(\"Training & Validation Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"training_curve.png\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_accs, val_accs = train()\n",
    "    plot(train_accs, val_accs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tifffile opencv-python matplotlib seaborn scikit-learn torchvision torch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
